{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: CUDAdrv.jl failed to initialize, GPU functionality unavailable (set JULIA_CUDA_SILENT or JULIA_CUDA_VERBOSE to silence or expand this message)\n",
      "└ @ CUDAdrv /Users/hongbinren/.julia/packages/CUDAdrv/mCr0O/src/CUDAdrv.jl:69\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using GPFlux\n",
    "using Plots; pyplot();\n",
    "using Random; Random.seed!(4);\n",
    "using Flux\n",
    "using Zygote\n",
    "using Optim\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CO2 data\n",
    "data = readdlm(\"CO2_data.csv\", ',')\n",
    "year = data[:,1]; co2 = data[:,2];\n",
    "# Split the data into training and testing data\n",
    "xtrain = year[year.<2004]; ytrain = co2[year.<2004];\n",
    "xtest = year[year.>=2004]; ytest = co2[year.>=2004];\n",
    "Xtrain = reshape(xtrain, 1, :);\n",
    "Xtest = reshape(xtest, 1, :);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "## standardize X and y\n",
    "# xtrain_mean = mean(xtrain)\n",
    "# ytrain_mean = mean(ytrain)\n",
    "# xtrain_std = std(xtrain)\n",
    "# ytrain_std = std(ytrain)\n",
    "# normalize_xtrain = @. (xtrain-xtrain_mean)/xtrain_std\n",
    "# normalize_ytrain = @. (ytrain-ytrain_mean)/ytrain_std\n",
    "\n",
    "# normalize_xtest = @. (xtest-xtrain_mean)/xtrain_std\n",
    "# normalize_ytest = @. (ytest-ytrain_mean)/ytrain_std\n",
    "\n",
    "# # input data\n",
    "# Xtrain = reshape(normalize_xtrain, 1, length(normalize_xtrain));\n",
    "# Xtest = reshape(normalize_xtest, 1, length(normalize_xtest));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.416666666666742"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel parameter initialization\n",
    "function median_distance_local(x)\n",
    "    n = length(x)\n",
    "    dist = []\n",
    "    for i in 1:n\n",
    "        for j in (i+1):n\n",
    "            push!(dist, abs(x[j]-x[i]))\n",
    "        end\n",
    "    end\n",
    "    median(dist)\n",
    "end\n",
    "\n",
    "l = median_distance_local(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralKernelNetwork{Tuple{Primitive{Tuple{IsoLinearKernel{Float64,Array{Float64,1}},IsoPeriodKernel{Float64,Array{Float64,1}},IsoGaussKernel{Float64,Array{Float64,1}}}},Linear{Array{Float64,2},Array{Float64,1}}}}((Primitive{Tuple{IsoLinearKernel{Float64,Array{Float64,1}},IsoPeriodKernel{Float64,Array{Float64,1}},IsoGaussKernel{Float64,Array{Float64,1}}}}((IsoLinearKernel{Float64,Array{Float64,1}}([0.0]), IsoPeriodKernel{Float64,Array{Float64,1}}([2.5964977151964685], [2.5964977151964685], [0.0]), IsoGaussKernel{Float64,Array{Float64,1}}([2.5964977151964685], [0.0]))), Linear{Array{Float64,2},Array{Float64,1}}([-0.953677773475647 0.5081663131713867 1.1278239488601685], [0.0])))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct kernels\n",
    "iso_lin_kernel = IsoLinearKernel([0.0])\n",
    "iso_per_kernel = IsoPeriodKernel([log(l)], [log(l)], [0.0])\n",
    "iso_rbf_kernel = IsoGaussKernel([log(l)], [0.0])\n",
    "\n",
    "# sum product network\n",
    "linear1 = Linear(3, 1)\n",
    "\n",
    "# NKN\n",
    "nkn = NeuralKernelNetwork(Primitive(iso_lin_kernel, iso_per_kernel, iso_rbf_kernel), linear1 |> f64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12649.398212166532"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build gp model\n",
    "zero_mean = ConstantMean()\n",
    "lnoise = [0.5*log(0.1)]\n",
    "gp = GaussProcess(zero_mean, nkn, lnoise)\n",
    "ps = params(gp)\n",
    "negloglik(gp, Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_fn(θ) = 8168.786645009569\n",
      "calc_g!(zeros(length(θ)), θ) = [1.6605581265988256, -0.9280937232592805, 183.26278236687276, 18.206178739938988, -21.018318818758416, 450.281802136068, -3500.417143156852, 0.36685830522379814, -5.828073578731588, -1450.4803973639912, -0.6891842204786371, -6048.116282535703]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calc_g!(G, θ)\n",
    "    dispatch!(gp, θ)\n",
    "    ps = params(gp)\n",
    "    gs = gradient(()->negloglik(gp, Xtrain, ytrain, λ=0.1), ps)\n",
    "\n",
    "    j = 1\n",
    "    for p in ps\n",
    "        lp = length(p)\n",
    "        G[j:j+lp-1] .= vec(gs.grads[p])\n",
    "        j += lp\n",
    "    end\n",
    "    G\n",
    "end\n",
    "\n",
    "function loss_fn(θ)\n",
    "    dispatch!(gp, θ)\n",
    "    negloglik(gp, Xtrain, ytrain, λ=0.1)\n",
    "end\n",
    "\n",
    "θ = flatten_params(ps)\n",
    "@show loss_fn(θ)\n",
    "@show calc_g!(zeros(length(θ)), θ)\n",
    "@test loss_fn(θ) ≈ negloglik(gp, Xtrain, ytrain, λ=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize negative loglik\n",
    "\n",
    "using Flux.Optimise: update!\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "loss = []\n",
    "for i in 1:2000\n",
    "    ll = negloglik(gp, Xtrain, ytrain)\n",
    "    push!(loss, ll)\n",
    "    if i==1 || i%200 == 0\n",
    "        @info \"step=$i, loss=$ll\"\n",
    "    end\n",
    "    gs = gradient(()->negloglik(gp, Xtrain, ytrain), ps)\n",
    "    for p in ps\n",
    "        update!(optimizer, p, gs[p])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
