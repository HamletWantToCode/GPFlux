{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using GPFlux\n",
    "using Plots; pyplot();\n",
    "using Random; Random.seed!(4);\n",
    "using Flux\n",
    "using Zygote\n",
    "using Optim\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using Distributions\n",
    "using Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CO2 data\n",
    "data = readdlm(\"data/AirPassengers.csv\", ',')\n",
    "year = data[2:end,2]; passengers = data[2:end,3];\n",
    "# Split the data into training and testing data\n",
    "oxtrain = year[year.<1958]; oytrain = passengers[year.<1958];\n",
    "oxtest = year[year.>=1958]; oytest = passengers[year.>=1958];\n",
    "\n",
    "#data preprocessing\n",
    "## standardize X and y\n",
    "xtrain_mean = mean(oxtrain)\n",
    "ytrain_mean = mean(oytrain)\n",
    "xtrain_std = std(oxtrain)\n",
    "ytrain_std = std(oytrain)\n",
    "xtrain = @. (oxtrain-xtrain_mean)/xtrain_std\n",
    "ytrain = @. (oytrain-ytrain_mean)/ytrain_std\n",
    "\n",
    "xtest = @. (oxtest-xtrain_mean)/xtrain_std\n",
    "ytest = @. (oytest-ytrain_mean)/ytrain_std\n",
    "\n",
    "## input data\n",
    "Xtrain = reshape(xtrain, 1, length(xtrain));\n",
    "Xtest = reshape(xtest, 1, length(xtest));\n",
    "Year = hcat(Xtrain, Xtest);\n",
    "Passengers = vcat(ytrain, ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xtrain, ytrain, xaxis=(\"year\"), yaxis=(\"passengers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel parameter initialization\n",
    "function median_distance_local(x)\n",
    "    n = length(x)\n",
    "    dist = []\n",
    "    for i in 1:n\n",
    "        for j in i:n\n",
    "            push!(dist, abs(x[j]-x[i]))\n",
    "        end\n",
    "    end\n",
    "    median(dist)\n",
    "end\n",
    "\n",
    "l = median_distance_local(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "heu_iso_linear_kernel = IsoLinearKernel([0.0])\n",
    "heu_iso_per_kernel = IsoPeriodKernel([log(l)], [log(l)], [0.0])\n",
    "heu_iso_rbf_kernel = IsoGaussKernel([log(l)], [0.0])\n",
    "\n",
    "heu_lin = Linear(3, 1) |> f64\n",
    "\n",
    "heu_player = Primitive(heu_iso_linear_kernel, heu_iso_per_kernel, heu_iso_rbf_kernel)\n",
    "heu_nkn = NeuralKernelNetwork(heu_player, heu_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct kernels\n",
    "iso_lin_kernel1 = IsoLinearKernel([0.0])\n",
    "iso_per_kernel1 = IsoPeriodKernel([log(l)], [log(l)], [0.0])\n",
    "iso_rbf_kernel1 = IsoGaussKernel([log(l/4.0)], [0.0])\n",
    "iso_rq_kernel1 = IsoRQKernel([log(2.0*l)], [log(0.2)], [0.0])\n",
    "iso_lin_kernel2 = IsoLinearKernel([0.0])\n",
    "iso_rq_kernel2 = IsoRQKernel([log(l)], [log(0.1)], [0.0])\n",
    "iso_rbf_kernel2 = IsoGaussKernel([log(l)], [0.0])\n",
    "iso_per_kernel2 = IsoPeriodKernel([log(l/4.0)], [log(l/4.0)], [0.0])\n",
    "\n",
    "\n",
    "# sum product network\n",
    "linear1 = Linear(8, 8) |> f64\n",
    "product1 = z -> GPFlux.Product(z, step=2)\n",
    "linear2 = Linear(4, 4) |> f64\n",
    "product2 = z -> GPFlux.Product(z, step=2)\n",
    "linear3 = Linear(2, 1) |> f64\n",
    "\n",
    "# mean function \n",
    "zero_mean = ConstantMean()\n",
    "\n",
    "# NKN\n",
    "player = Primitive(iso_lin_kernel1, iso_per_kernel1, iso_rbf_kernel1, iso_rq_kernel1,\n",
    "                     iso_lin_kernel2, iso_rq_kernel2, iso_rbf_kernel2, iso_per_kernel2)\n",
    "nkn = NeuralKernelNetwork(player, linear1, product1, linear2, product2, linear3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from prior\n",
    "zero_mean = ConstantMean()\n",
    "gp_prior = GaussProcess(zero_mean, nkn, [-Inf])\n",
    "prior_dist = MvNormal(gp_prior, Xtrain)\n",
    "samples = rand(prior_dist, 5)\n",
    "plot(xtrain, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build gp model\n",
    "zero_mean = ConstantMean()\n",
    "lnoise = [0.5*log(0.1)]\n",
    "gp = GaussProcess(zero_mean, nkn, lnoise)\n",
    "ps = GPFlux.params(gp)\n",
    "negloglik(gp, Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "function calc_g!(G, θ)\n",
    "    dispatch!(gp, θ)\n",
    "    ps = GPFlux.params(gp)\n",
    "    gs = gradient(()->negloglik(gp, Xtrain, ytrain), ps)\n",
    "\n",
    "    j = 1\n",
    "    for p in ps\n",
    "        lp = length(p)\n",
    "        G[j:j+lp-1] .= vec(gs.grads[p])\n",
    "        j += lp\n",
    "    end\n",
    "    G\n",
    "end\n",
    "\n",
    "function loss_fn(θ)\n",
    "    dispatch!(gp, θ)\n",
    "    negloglik(gp, Xtrain, ytrain)\n",
    "end\n",
    "\n",
    "θ = flatten_params(ps)\n",
    "@show loss_fn(θ)\n",
    "@show calc_g!(zeros(length(θ)), θ)\n",
    "@test loss_fn(θ) ≈ negloglik(gp, Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "θ₀ = copy(θ)\n",
    "res = optimize(loss_fn, calc_g!, θ₀, GradientDescent(), Optim.Options(g_tol=1e-3, store_trace=true,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize negative loglik\n",
    "\n",
    "using Flux.Optimise: update!\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "loss = []\n",
    "for i in 1:5000\n",
    "    ll = negloglik(gp, Xtrain, ytrain)\n",
    "    push!(loss, ll)\n",
    "    if i==1 || i%100 == 0\n",
    "        @info \"step=$i, loss=$ll\"\n",
    "    end\n",
    "    gs = gradient(()->negloglik(gp, Xtrain, ytrain), ps)\n",
    "    for p in ps\n",
    "        update!(optimizer, p, gs[p])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y, pred_σ2 = predict(gp, Year, Xtrain, ytrain)\n",
    "pred_σ = sqrt.(pred_σ2)\n",
    "pred_oy = @. pred_y*ytrain_std+ytrain_mean\n",
    "pred_oσ = @. pred_σ*ytrain_std\n",
    "\n",
    "plot(year, pred_oy, ribbon=pred_oσ, title=\"Time series prediction\",label=\"95% predictive confidence region\")\n",
    "scatter!(oxtest, oytest, label=\"Observations(test)\", color=:red)\n",
    "scatter!(oxtrain, oytrain, label=\"Observations(train)\", color=:black)\n",
    "plot!(xaxis=(\"Year\"), yaxis=(\"CO₂ concentration\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
